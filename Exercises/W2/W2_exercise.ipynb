{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Background subtraction\n",
    "\n",
    "This python notebook includes all the exercises from this session. All the needed setup, I/O and user-interaction code is already provided to let you concentrate on this week's topic.<br>\n",
    "Please run all the provided code in order before running yours.<br>\n",
    "\n",
    "\n",
    "## 1. Bluescreen\n",
    "### 1.A Single pixel model\n",
    "Extract foreground objects in bluescreen movie footage. The blue background color should be specified by a single color value [r, g, b]. You may obtain such a value by using the provided notebook widget to select one or more blue pixels on the first frame of the footage. To determine whether a given pixel should be foreground or background, threshold the absolute distance of its value to the reference value, i.e.\n",
    "\n",
    "$$\\left\\lVert[r, g, b] - [r_0, g_0, b_0]\\right\\rVert < t$$\n",
    "\n",
    "Based on pixelwise decisions, a mask can be created to specify foreground and background.<br>\n",
    "Try different values for the threshold and the reference color. To test your results, you can use the short video provided. Note that not the whole background consists of bluescreen.\n",
    "To overcome this problem, you can use the precomputed mask provided into the variable `mask`.\n",
    "\n",
    "### 1.B Exemplar set model\n",
    "To further improve the results, specify the blue background by an exemplar set of blue background pixels. You may select this set using the same widget as in the previous point. After computing mean $\\mu$ and covariance matrix $\\Sigma$ of the pixel values, the Mahalanobis distance $M(x, \\mu, \\Sigma)$ can be used to decide whether a color value $x$ originated from the background or the foreground.\n",
    "\n",
    "$$M(x, \\mu, \\Sigma) = \\sqrt{(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$$\n",
    "\n",
    "## 2. Per-pixel Model\n",
    "Probably you have noticed that the approach in the previous task failed in the upper region of the background, which was not covered with blue sheets, for which we provided the `mask`. To handle more complex scenarios, extend the background model to a per-pixel model. For each pixel, compute the mean and the covariance of its values over a number of frames which do not contain foreground objects. You may then use the Mahalanobis distance to classify pixels in sequences containing foreground objects. You can use the same threshold for all pixels.<br>\n",
    "To create the model, use jugglingBG.avi. This scene was captured for several frames without foreground objects. Based on the background model, foreground pixels can then be identified and masks can be created for jugglingTest.avi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information for this tutorial:\n",
    "\n",
    "Images are represented as numpy arrays, which are fixed-dimensional arrays. Videos are represented as arrays of images.<br>\n",
    "In this tutorial each pixel takes a RGB value within the range [0-255] and is represented as a 16-bit signed integer, to allow signed operations without subtle overflow bugs.\n",
    "\n",
    "you will need to visualize your results, thus to printout an image use:\n",
    "\n",
    "`imshow(image)`\n",
    "\n",
    "You can read pixel values inside an image by accessing the corresponding pixel coordinates in the array. The following reads the green component (1) of pixel at location (10, 20) of the 5th frame (index 4):\n",
    "\n",
    "`g = vid[4, 10, 20, 1]`\n",
    "\n",
    "Of course you can also change pixel values in the same way. We recommend copying an image before editing. To copy an image:\n",
    "\n",
    "`im_copy = np.array(im)` (`np` is the short name for `numpy` which is recognized by python when importing numpy with `import numpy as np`)\n",
    "\n",
    "With numpy it is also possible to refer to slices of a given array by specifying the kept dimensions in the slice with `:`. For example, if we want to access the red channel of an RGB image `im` with shape `(height, width, 3)`, we can write `im[:, :, 0]`, which refers to the whole image data for the red channel only. We can optionally specify a range to be kept along a direction by writing the extreme indices around the `:` as in `min:max`. For example, accessing a patch within the pixel coordinates `(h0, w0)`, `(h1, w1)` with h0 < h1 and w0 < w1 can be done with `im[h0:h1, w0:w1, :]`.<br>\n",
    "You can also index arrays based on conditions: for example to set to black all pixels with a blue component higher than 200 you can write `im[im[:, :, 2] > 200] = 0`.<br>\n",
    "These references can be used both for reading an image slice and for writing a whole slice at once, without looping over it.\n",
    "\n",
    "When doing operations between numpy arrays, all operations are executed element-wise (except for the `@` operator that performs the usual matrix multiplication). This requires the shapes (dimensions) of the involved arrays to match or to be compatible according to broadcasting rules, which are usually intuitive. An example of broadcasting is when adding a pixel value `p=np.array([70, 128, 255])` to an image `im` with shape `(height, width, 3)`: the operation is legal and the pixel value is added independently to each pixel in the image. A complete reference of numpy broadcasting rules (not necessary for this tutorial, but very useful for numpy python programming) can be found in https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html . \n",
    "\n",
    "In the following we list some useful functions:\n",
    "\n",
    "`np.array(a)`: returns a copy of `a` as a numpy array. Argument `a` does not need to be a numpy array, it can be any array-like object, e.g. a python list. https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html<br>\n",
    "`np.empty(shape, dtype)`: returns a new empty array with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.empty.html<br>\n",
    "`np.ones(shape, dtype)`: returns a new array filled with ones with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html<br>\n",
    "`np.zeros(shape, dtype)`: returns a new array filled with zeros with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html<br>\n",
    "`np.eye(N)` : builds the identity matrix of order `N`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html<br>\n",
    "`np.reshape(a, newshape)`: returns a reshaped view of the input array `a` having shape `newshape`, which should be specified as a tuple of integers. https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html<br>\n",
    "`np.linalg.norm(x)`: returns the L2 norm of array `x`. You can also specify a keyword argument `axis` to compute the norm only along a specific dimension (the result will have the same shape as `x`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html<br>\n",
    "`np.transpose(a)` : returns the transposed of array `a`, whose shape has reversed order with respect to `a`. Alias `a.T`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html<br>\n",
    "`np.linalg.inv(a)` : returns the multiplicative inverse of matrix `a`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html<br>\n",
    "`np.matmul(a, b)` : returns the matrix multiplication of `a` multiplied by `b`. Alias `a @ b`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html<br>\n",
    "`np.sum(a)` : returns the sum of all the elements of array `a`. You can specify a keyword argument `axis` to compute the sum only along a specific dimension (the result will have the same shape as `a`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html<br>\n",
    "`np.mean(a)` : returns the mean value of all the elements of array `a`. You can specify a keyword argument `axis` to compute the mean only along a specific dimension (the result will have the same shape as `a`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html<br>\n",
    "`np.cov(m)` : build the covariance matrix of array `a` where each row represents a variable and each column represents an observation.  https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1 - SETUP CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell installs required packages into the virtual machine that will run your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffprobe in /home/karlo/.local/lib/python3.10/site-packages (0.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg in /home/karlo/.local/lib/python3.10/site-packages (1.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-video in /home/karlo/.local/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from scikit-video) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/karlo/.local/lib/python3.10/site-packages (from scikit-video) (1.23.3)\n",
      "Requirement already satisfied: scipy in /home/karlo/.local/lib/python3.10/site-packages (from scikit-video) (1.9.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image in /home/karlo/.local/lib/python3.10/site-packages (0.19.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (2022.8.12)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (2.8.6)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (2.22.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/lib/python3/dist-packages (from scikit-image) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/karlo/.local/lib/python3.10/site-packages (from scikit-image) (1.23.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->scikit-image) (2.4.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /home/karlo/.local/lib/python3.10/site-packages (8.0.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/karlo/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/karlo/.local/lib/python3.10/site-packages (from ipywidgets) (6.16.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/karlo/.local/lib/python3.10/site-packages (from ipywidgets) (8.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/karlo/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/karlo/.local/lib/python3.10/site-packages (from ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: psutil in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: packaging in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/karlo/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: backcall in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: stack-data in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /home/karlo/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/karlo/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/karlo/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/karlo/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: entrypoints in /home/karlo/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: wcwidth in /home/karlo/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (2.4.7)\n",
      "Requirement already satisfied: asttokens in /home/karlo/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.8)\n",
      "Requirement already satisfied: executing in /home/karlo/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: pure-eval in /home/karlo/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/karlo/.local/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (4.37.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/karlo/.local/lib/python3.10/site-packages (from matplotlib) (1.23.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffprobe\n",
    "!pip install ffmpeg\n",
    "!pip install scikit-video\n",
    "!pip install scikit-image\n",
    "!pip install ipywidgets\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages to read videos, make interactive widgets and plot images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "from ipywidgets import interactive, widgets\n",
    "from IPython.display import display\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the test video bluescreen.avi in `bluescreen` and the upper region mask into `umask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video information:\n",
      "Number of frames:  43\n",
      "Frame width (pixels):  516\n",
      "Frame height (pixels):  389\n",
      "Video array shape:  (43, 389, 516, 3)\n"
     ]
    }
   ],
   "source": [
    "bluescreen = np.array(skvideo.io.vread(\"bluescreen.avi\"), dtype=np.int16)\n",
    "numframes, height, width, channels = np.shape(bluescreen)\n",
    "print(\"Video information:\")\n",
    "print(\"Number of frames: \", numframes)\n",
    "print(\"Frame width (pixels): \", width)\n",
    "print(\"Frame height (pixels): \", height)\n",
    "print(\"Video array shape: \", np.shape(bluescreen))\n",
    "\n",
    "umask = skimage.io.imread(\"mask.bmp\")//255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a \\*wonderful\\* user interface we have prepared for you to select any number of points on the first frame of the video.\n",
    "\n",
    "Use the x slider to move vertically and use the y slider to move horizontally (x and y reflect indexing in the image array).<br>\n",
    "Press \"Update image\" when you want to see where you moved your cursor within the image, and press \"Remember this point\" when you want to store the current selected point into the python list `selected_image_locations`.\n",
    "\n",
    "\n",
    "`selected_image_locations` will contain all selected locations stored as couples of integers, taking the format: [(x1, y1), (x2, y2), (x3, y3) ...]\n",
    "\n",
    "The image will show a red cross where there is the current temporary selection, and green crosses on all stored locations.\n",
    "\n",
    "If you are not familiar with numpy arrays, we suggest to read through the code of `display_selections` and `draw_cross` as further examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7288797a2e4b9ca04ffe8bd2703e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Remember this point', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4ccfec7a9d44b98045dd98f2fcdb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=194, description='x', max=388), IntSlider(value=257, description='y', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_image_locations = list()\n",
    "\n",
    "def draw_cross(im, cx, cy, l, w, col):\n",
    "    dimx, dimy = np.shape(im)[:2]\n",
    "    im[max(0, cx-l):min(cx+l, dimx-1), max(0, cy-w):min(dimy-1, cy+w)] = col\n",
    "    im[max(0, cx-w):min(dimx-1, cx+w), max(0, cy-l):min(dimy-1, cy+l)] = col\n",
    "\n",
    "\n",
    "def display_selections(x, y):\n",
    "    tmp_im = np.array(bluescreen[0]*umask)\n",
    "    for px, py in selected_image_locations:\n",
    "        draw_cross(tmp_im, px, py, 1, 5, (0, 255, 0))\n",
    "    draw_cross(tmp_im, x, y, 1, 5, (255, 0, 0))\n",
    "    imshow(tmp_im)\n",
    "    \n",
    "interactive_plot = interactive(display_selections,{'manual': True, 'manual_name': 'Update image'}, x=(0, height-1, 1), y=(0, width-1, 1))\n",
    "button = widgets.Button(description=\"Remember this point\")\n",
    "xslider = interactive_plot.children[0]\n",
    "yslider = interactive_plot.children[1]\n",
    "button.on_click(lambda b: selected_image_locations.append((xslider.value, yslider.value)))\n",
    "display(button)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1.A - PUT SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (389,516,3) (389,516) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m bgmask[np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(bluescreen[\u001b[38;5;241m0\u001b[39m, :, :, :] \u001b[38;5;241m-\u001b[39m ref_rgb, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m THRESHOLD] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# and visualize your results on the first frame. Do they look reasonable?\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m imshow(bluescreen[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mbgmask)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (389,516,3) (389,516) "
     ]
    }
   ],
   "source": [
    "# A few basic code hints this time, just in case it is the very first time you code in Python :)\n",
    "# of course this is not a template for the 'best' solution, you are encouraged to change everything you want!\n",
    "\n",
    "# First we take the x and y pixel coordinates of the first selection made at the previous step. \n",
    "# Notice that selected_image_location[0] is a tuple of 2 elements, which we can assign to two scalar variables at once. If the dimensions don't match (like assigning a couple to three variables), Python will throw an error\n",
    "selx, sely = selected_image_locations[0]\n",
    "\n",
    "# get the [r0, g0, b0] values that model our background in this simple single-pixel model\n",
    "ref_rgb = bluescreen[0, selx, sely, :]\n",
    "\n",
    "# set a threshold, you can tune it experimentally after seeing the results\n",
    "THRESHOLD = 10\n",
    "\n",
    "# initialize the background mask, it will need to be a 0-1 array of the same sizes of our video frames, so that each 0-1 value corresponds to a pixel being assigned to class background (0) or foreground (1)\n",
    "bgmask = np.array(np.zeros((height, width)), dtype=np.int8)\n",
    "\n",
    "# now classify each pixel according to the single-pixel model\n",
    "'''\n",
    "for h in range(height):\n",
    "    for w in range(width):\n",
    "        if np.linalg.norm(bluescreen[0, h, w, :] - ref_rgb) < THRESHOLD:\n",
    "            bgmask[h, w] = 1\n",
    "'''\n",
    "\n",
    "# alternatively you can also do it with one line of code using conditional indexing:\n",
    "bgmask[np.linalg.norm(bluescreen[0, :, :, :] - ref_rgb, axis=2) < THRESHOLD] = 1\n",
    "\n",
    "# and visualize your results on the first frame. Do they look reasonable?\n",
    "imshow(bluescreen[0]*bgmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1.B - PUT SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this time the Mahalanobis distance for the thresholding, with a global mean and covariance of the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2 - SETUP CODE\n",
    "(installs and imports from the Exercise 1 should be run anyway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the test video jugglingTest.avi in `testvid` and the background reference video jugglingBG.avi into `bgvid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgvid = np.array(skvideo.io.vread(\"jugglingBG.avi\"), dtype=np.int16)\n",
    "testvid = np.array(skvideo.io.vread(\"jugglingTest.avi\"), dtype=np.int16)\n",
    "\n",
    "bgnumframes, bgheight, bgwidth, bgchannels = np.shape(bgvid)\n",
    "print(\"jugglingBG.avi video information:\")\n",
    "print(\"Number of frames: \", bgnumframes)\n",
    "print(\"Frame width (pixels): \", bgwidth)\n",
    "print(\"Frame height (pixels): \", bgheight)\n",
    "print(\"Video array shape: \", np.shape(bgvid))\n",
    "\n",
    "print()\n",
    "testnumframes, testheight, testwidth, testchannels = np.shape(testvid)\n",
    "print(\"jugglingTest.avi video information:\")\n",
    "print(\"Number of frames: \", testnumframes)\n",
    "print(\"Frame width (pixels): \", testwidth)\n",
    "print(\"Frame height (pixels): \", testheight)\n",
    "print(\"Video array shape: \", np.shape(testvid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2 - PUT SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use again the Mahalanobis distance for the thresholding, but with a per-pixel mean and covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE EXAM QUESTION\n",
    "\n",
    "![alt text](F1.png \"Figure 1\")\n",
    "\n",
    "![alt text](Q1.png \"Question 1\")\n",
    "\n",
    "![alt text](Q2.png \"Question 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space for answer:\n",
    "\n",
    "...\n",
    "(double click here to edit this markdown cell!)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "Luca Cavalli (luca.cavalli@inf.ethz.ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
